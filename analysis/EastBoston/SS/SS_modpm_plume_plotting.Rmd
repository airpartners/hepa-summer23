---
editor_options: 
  markdown: 
    wrap: 72
---

# East Boston Plume Plotting (for Mod-PM)

Plot various plumes before and after HEPA installation to compare their
heights, widths, decay constants, etc.

## STOP

**HAVE YOU RUN `SS_modpm_cleaning`?** *This file loads a dataframe
created from running `LF_modpm_cleaning`. Make sure you run that file
first (if you haven't already) before running this file.*

This file is used to analyze decay constants and complete plume
visualizations for the East Boston Mod-PM data.

```{r}
# import necessary libraries
library(tidyverse)
library(data.table)
library(scales)
library(pracma)
```

```{r, setup, include=FALSE}
# set working directory
knitr::opts_knit$set(root.dir = "~/AirPartners/hepa-summer23")
```

```{r}
# check file path for working directory
if (!endsWith(getwd(), "hepa-summer23")) {
  stop("Incorrect working directory")
}
```

```{r}
# set path to data
path_to_data <- "cleaning/EastBoston/SS/"
```

## Load data

```{r}
# Load Mod-PM data from RData file
load(paste0(path_to_data, "cleaned_modpm.RData"))
```

## Main Code Run

```{r}
# Pre-processing to add relevant columns
my_df <- main_df %>%
  # Round date to nearest ten minutes
  mutate(date_round = round_date(date, unit = "10 min")) %>%
  # Get day of the week as integer from 1 to 7
  mutate(wkdy = wday(date)) %>%
  # Classify as weekday or weekend
  mutate(is_wknd = wkdy %in% c(1, 7)) %>%
  # Extract time of the day from datetime
  mutate(time = as.POSIXct(as.ITime(date_round), format = "%H:%M:%S"))
my_df
```

```{r}
# Calculate summary statistics for every ten minutes
graph_main_df <- my_df %>%
  # Gather dataframe to create single variable for measurements
  pivot_longer(c(pm1, pm25, pm10), 
               names_to = "particle", values_to = "reading") %>%
  # For every 10 minutes for given case, environment, particle, weekday/end
  group_by(is_wknd, time, case, environment, particle) %>%
  # Find summary statistics
  summarise(mean = mean(reading),
          median = median(reading), 
          q5 = quantile(reading, probs = 0.05), 
          q25 = quantile(reading, probs = 0.25),
          q75 = quantile(reading, probs = 0.75),
          q95 = quantile(reading, probs = 0.95),
          sd = sd(reading),
          .groups = 'drop')
graph_main_df
```

```{r}
# Calculate average baseline parameter and mean parameters, which will be used
# to define the baseline and the minimum height of peaks
pm25_indoor <- graph_main_df[graph_main_df$environment=='indoor' & graph_main_df$particle=='pm25',]
pm_baseline <- pm25_indoor %>%
  group_by(case) %>%
  summarise(mean = mean(mean))
pm_min_heights <- pm25_indoor %>%
  group_by(case) %>%
  summarise(median = mean(median))
```


# Helper functions for plume analysis

```{r}
# Find the first local minimum before/after the index of peak_row in y
# that occurs below the min_threshold.
get_local_valleys <- function(data, peaks, min_threshold) {
  # Iterate through rows of peaks matrix and get valleys before peaks
  for (row in 1:nrow(peaks)) {
    idx <- peaks[row, 2]
    n <- TRUE
    # create while loop to check for local minima
    while (n) {
      # if we're at the end of y, break out of loop
      if (idx == 1) {
        n <- FALSE
      } else {
        # otherwise, get slope (approximately)
        slope <- data[idx] - data[idx - 1]
        # print(paste("Idx", idx, "Data[]:", data[idx], "Data[-1]", data[idx-1], "Slope:", slope))
        if (data[idx] <= min_threshold && slope < 0) {
          # print(paste("Valley at index", idx))
          n <- FALSE
        } else {
          idx <- idx - 1
        }
      }
    }
    # set values of matrix so that column 3 is index of valley before peak
    peaks[row, 3] <- idx
  }
  # Repeat process for valleys after peaks
  for (row in 1:nrow(peaks)) {
    idx <- peaks[row, 2]
    n <- TRUE
    # create while loop to check for local minima
    while (n) {
      # if we're at the end of y, break out of loop
      if (idx == length(data)) {
        n <- FALSE
      } else {
        # otherwise, get slope (approximately)
        slope <- data[idx + 1] - data[idx]
        # print(paste("Slope:", slope))
        if (data[idx] <= min_threshold && slope > 0) {
          n <- FALSE
        } else {
          idx <- idx + 1
        }
      }
    }
    # set values of matrix so that column 4 is index of valley after peak
    peaks[row, 4] <- idx
  }
  # Convert to dataframe and remove duplicate valleys
  colnames(peaks) <- c("peak_hgt", "peak", "valley_b", "valley_a")
  peaks_df <- as.data.frame(peaks)
  
  # Sorting peaks_df by peak in descending order
  peaks_df <- peaks_df[order(-peaks_df$peak),]
  peaks_df
  
  # Drop duplicate valleys, keeping highest peak for each duplicate
  result_peaks <- peaks_df[!duplicated(peaks_df[, c("valley_b", "valley_a")]),]
  result_peaks
}
```


```{r}
# Exponential curve fitting for air quality data; returns dataframe containing
# k-values of curves (MK II)
# NOTE: if the curve is too small or doesn't contain enough information for this
# computation, peak will be omitted from final return
curve_fitting <- function(data, peaks) {
  # Create empty DataFrame for storing k values
  alphas.data <- data.frame(
    "peak_idx" = numeric(0),
    "valley_idx_b" = numeric(0),
    "valley_idx_a" = numeric(0),
    "peak_hgt" = numeric(0),
    "k_val" = numeric(0),
    "conv_tol" = numeric(0),
    "cumm_pm" = numeric(0)
  )
  # Define parameters for curve fitting function for each row
  for (row in 1:nrow(peaks)) {
    row <- as.double(row)
    # Find time range of the peak to first valley
    i_range <- peaks[row, 2]:peaks[row, 4]
    t <- i_range - peaks[row, 2] + 1
    # Find the data points of the section
    sect <- data$y[i_range]
    # Create DataFrame with these points 
    df <- data.frame(t = t, y = sect)
    # Get exponential fit
    f <- function(x, a, b) {a * exp(b * x)}
    fm_lm <- lm(log(y) ~ t, data=df)
    st <- list(a = exp(coef(fm_lm)[1]), b = coef(fm_lm)[2])
    fit <- try(nls(y ~ f(t, a, b), data = df, start = st))
    # Get parameters of the fit
    params <- coef(fit)
    # Extract the decay constant value (b)
    alpha <- as.double(params["b"])
    # Get achieved convergence tolerance as metric for accuracy of fit
    # NOTE: R^2 value can be calculated but is not a useful metric
    # for nonlinear models
    conv <- fit$convInfo$finTol
    # Calculate cumulative PM for each plume
    plume_pm <- sum(data$y[peaks[row, 3]:peaks[row, 4]])
    
    # Add alpha to dataframe
    alphas.newdata <- data.frame(
      "peak_idx" = c(peaks[row, 2]),
      "valley_idx_b" = c(peaks[row, 3]),
      "valley_idx_a" = c(peaks[row, 4]),
      "peak_hgt" = c(peaks[row, 1]),
      "k_val" = c(alpha),
      "conv_tol" = c(conv),
      "cumm_pm" = c(plume_pm)
    )
    alphas.data <- rbind(alphas.data, alphas.newdata)
  }
  alphas.data <- arrange_all(alphas.data)
  alphas.data <- alphas.data[order(alphas.data$peak_hgt), ]
}
```

### Main Plume Analysis

Below is a sample analysis and output for PM2.5 in the dataset. This gives a 
preview, as well as plots some graphs, that can be used to visualize the decay
analysis process.

First, we separate the data based on whether the HEPA purifier was there or not.
Then, we detect the plumes through peak detection.
```{r}
# Get admin ratios
my_df_subset <- my_df[my_df$participant_id=='front' & my_df$environment=='indoor',]
my_df_subset_smoothed <- lowess(my_df_subset$pm10, f=0.005)
plot(my_df_subset_smoothed,
  type = "l",
  main = "Indoor/Outdoor Ratio",
  xlab = "Time (indices)",
  ylab = "Ratio of indoor/outdoor concentrations",
  col = "navy")
  grid()
```
```{r}
peaks <- findpeaks(my_df_subset_smoothed$y,
                   nups = 1,
                   ndowns = 2,
                   minpeakheight = as.numeric(pm_min_heights[pm_min_heights$case=='off', 'median']),
                   # minpeakheight = 5,
                   minpeakdistance = 1,
                   threshold = 0)

plot(my_df_subset_smoothed,
  type = "l",
  main = "Indoor/Outdoor Ratio",
  xlab = "Time (indices)",
  ylab = "Ratio of indoor/outdoor concentrations",
  col = "navy")
  grid()
points(peaks[, 2], peaks[, 1], pch = 20, col = "maroon")
```

```{r}
peaks <- get_local_valleys(my_df_subset_smoothed$y,
                           peaks = peaks,
                           min_threshold = as.numeric(pm_baseline[pm_baseline$case=='off', 'mean']))
                          # min_threshold = 5)
plot(my_df_subset_smoothed,
  type = "l",
  main = "Peaks and Valleys of Air Quality Data",
  xlab = "Time (indices)",
  ylab = "Ratio of indoor/outdoor concentrations",
  col = "navy")
  grid()
points(peaks[, 2], peaks[, 1], pch = 20, col = "maroon")
# points(peaks[, 3], my_df_subset$pm1[peaks[, 3]], pch = 20, col = "yellow")
points(peaks[, 4], my_df_subset_smoothed$y[peaks[, 4]], pch = 20, col = "green")
```


```{r}
# Separate my_df by before vs. after
my_df_before <- my_df_subset[my_df_subset$case=='off',]
my_df_after  <- my_df_subset[my_df_subset$case=='on',]

# Lowess smoothing
my_df_before_smoothed <- lowess(my_df_before$pm10, f=0.005)
my_df_after_smoothed <- lowess(my_df_after$pm10, f=0.005)

# Get peaks from before and after
peaks_b <- findpeaks(my_df_before_smoothed$y,
                     nups = 1,
                     ndowns = 2,
                     minpeakheight = as.numeric(pm_min_heights[pm_min_heights$case=='off', 'median']),
                     # minpeakheight = 5,
                     minpeakdistance = 1,
                     threshold = 0)
peaks_a <- findpeaks(my_df_after_smoothed$y,
                     nups = 1,
                     ndowns = 2,
                     minpeakheight = as.numeric(pm_min_heights[pm_min_heights$case=='on', 'median']),
                     # minpeakheight = 1,
                     minpeakdistance = 1,
                     threshold = 0)
```


The below script gets the "valleys" of the plumes, which are where the plumes
both level off and fall below a certain mean threshold. In this case, the plumes
have to fall below the average PM concentration for each case.
```{r}
# Get valleys before and after to isolate each plume
peaks_b <- get_local_valleys(my_df_before_smoothed$y,
                             peaks = peaks_b,
                             min_threshold = as.numeric(pm_baseline[pm_baseline$case=='off', 'mean']))
                             # min_threshold = 0.8)
peaks_a <- get_local_valleys(my_df_after_smoothed$y,
                             peaks = peaks_a,
                             min_threshold = as.numeric(pm_baseline[pm_baseline$case=='on', 'mean']))
                             # min_threshold = 5.)
```


Below shows the locations of these peaks and valleys. Note that certain peaks
are not detected due to the distances between plumes. This algorithm ignores
"abnormal plumes," or plumes that are too close to each other resulting in the 
exponential decay to be distorted.

TODO: fix
```{r}

# Plot peaks and valleys on top of current time series with valleys 
# (sanity check)
plot(my_df_before_smoothed,
  type = "l",
  main = "Indoor/Outdoor Ratio",
  xlab = "Time (indices)",
  ylab = "Ratio of indoor/outdoor concentrations",
  col = "navy")
  grid()
points(peaks_b[, 2], peaks_b[, 1], pch = 20, col = "maroon")
# points(peaks_b[, 3], my_df_before_smoothed$y[peaks_b[, 3]], pch = 20, col = "yellow")
points(peaks_b[, 4], my_df_before_smoothed$y[peaks_b[, 4]], pch = 20, col = "green")
```
Now we can calculate this plume analysis for before and after the HEPA purifier
was installed for each plume.
```{r}
# perform decay analysis
decays_before <- curve_fitting(my_df_before_smoothed, peaks = peaks_b)
decays_before
```

```{r}
# perform decay analysis
decays_after <- curve_fitting(my_df_after_smoothed, peaks = peaks_a)
decays_after
```

Let's view some of these peaks.

```{r}
# Before HEPA deployment
peak_idxs <- c(
  tail(decays_after, n=1)$valley_idx_b,
  tail(decays_after, n=1)$valley_idx_a
)
my_df_after %>%
  ggplot(aes(x = as.numeric(row.names(my_df_after)))) +
  # Plot the highest pm25 plume
  geom_line(aes(y = pm25)) +
  # Labels
  xlab('Time Since Sensor Deployment (10min)') + 
  ylab('PM2.5 Levels') +
  # ylim(0,500) +
  # Add fun theme
  theme_bw() +
  # Scale to just around the plume
  coord_cartesian(xlim = peak_idxs)
```
You may notice in the table that this particular peak has a really low decay 
constant. This probably results from the peak having a really low height and 
longer width. Overall, we can see that when summarizing the results for indoor
pm25 concentrations, the decay constants are not super telling, but the total 
exposure measurements by looking at the areas under the curves are.

We can summarize the statistics for all plumes in a small table.

```{r}
# Merge decay tables, adding a column indicating whether HEPA installed or not
decays_before$hepa <- FALSE
decays_after$hepa <- TRUE
all_decays <- merge(decays_before, decays_after, all = TRUE)
all_decays

# Get index of when HEPA was installed
hepa_install_idx <- match(TRUE, all_decays$hepa)

# Create summary of decay values for before and after
all_decays["hepa_installed"] <- all_decays["peak_idx"] >= hepa_install_idx
all_decays["peak_width"] <- all_decays["valley_idx_a"] - all_decays["valley_idx_b"]

decay_sum <-
  all_decays %>%
    group_by(hepa) %>%
    filter(peak_width > 5) %>%
    summarize(
      # kval
      k_val_mean = mean(k_val, na.rm = TRUE),
      k_val_median = median(k_val, na.rm = TRUE),
      k_val_min = min(k_val, na.rm = TRUE),
      k_val_max = max(k_val, na.rm = TRUE),
      # peak heights
      peak_hgt_mean = mean(peak_hgt, na.rm = TRUE),
      peak_hgt_median = median(peak_hgt, na.rm = TRUE),
      peak_wdh_min = min(peak_width, na.rm = TRUE),
      peak_wdh_max = max(peak_width, na.rm = TRUE),
      # peak widths
      peak_wdh_mean = mean(peak_width, na.rm = TRUE),
      peak_wdh_median = median(peak_width, na.rm = TRUE),
      peak_wdh_min = min(peak_width, na.rm = TRUE),
      peak_wdh_max = max(peak_width, na.rm = TRUE),
      # cumulative PM
      total_plume_area = sum(cumm_pm, na.rm = TRUE)
    )
decay_sum
```
Note how the mean *k* value increased; this is because the exponential decay of
PM2.5 after the HEPA purifier was installed was *faster*. In essence, particles 
filtered out of the room at a greater rate compared to before.


## Plume Analysis by Participant

The rest of this file calculated statistics on plume reduction
throughout the dataset. Below summarizes all that analysis into one
function, creating reduction statistics, and performing that function on
the dataset as it is grouped by participation, room, and PM.

```{r}
plume_redus <- function(data, id, env, pm) {
  sub_data <- data[data$participant_id == id & data$environment == env,]
  # Drop NA data
  sub_data <- sub_data[!is.na(sub_data[[pm]]),]
  # Separate my_df by before vs. after
  my_df_before <- sub_data[sub_data$case=='off',]
  my_df_after  <- sub_data[sub_data$case=='on',]
  # Smooth the curves
  my_df_before_smoothed <- lowess(my_df_before[[pm]], f=0.005)
  my_df_after_smoothed  <- lowess(my_df_after[[pm]], f=0.005)
  
  # Calculate average baseline parameter and mean parameters, which will be used
  # to define the baseline and the minimum height of peaks
  pm_indoor <- graph_main_df[graph_main_df$environment==env & graph_main_df$particle==pm,]
  pm_baseline <- pm_indoor %>%
    group_by(case) %>%
    summarise(mean = mean(mean))
  pm_min_heights <- pm_indoor %>%
    group_by(case) %>%
    summarise(mean = mean(median))

  # Get peaks from before and after
  peaks_b <- findpeaks(my_df_before_smoothed$y,
                       nups = 1,
                       ndowns = 2,
                       minpeakheight = as.numeric(pm_min_heights[pm_min_heights$case=='off', 'mean']),
                       # minpeakheight = 1,
                       minpeakdistance = 1,
                       threshold = 0)
  peaks_a <- findpeaks(my_df_after_smoothed$y,
                       nups = 1,
                       ndowns = 2,
                       minpeakheight = as.numeric(pm_min_heights[pm_min_heights$case=='on', 'mean']),
                       # minpeakheight = 1,
                       minpeakdistance = 1,
                       threshold = 0)

  peaks_b <- get_local_valleys(my_df_before_smoothed$y,
                               peaks = peaks_b,
                               min_threshold = as.numeric(pm_baseline[pm_baseline$case=='off', 'mean']))
                               # min_threshold = 5)
  peaks_a <- get_local_valleys(my_df_after_smoothed$y,
                               peaks = peaks_a,
                               min_threshold = as.numeric(pm_baseline[pm_baseline$case=='on', 'mean']))
                               # min_threshold = 5)
  
  # perform decay analysis for before and after
  decays_before <- curve_fitting(my_df_before_smoothed, peaks = peaks_b)
  decays_after  <- curve_fitting(my_df_after_smoothed, peaks = peaks_a)
  
  # Merge decay tables, adding a column indicating whether HEPA installed or not
  decays_before$hepa <- FALSE
  decays_after$hepa <- TRUE
  all_decays <- merge(decays_before, decays_after, all = TRUE)
  
  # Get index of when HEPA was installed
  hepa_install_idx <- match(TRUE, all_decays$hepa)
  
  # Create summary of decay values for before and after
  all_decays["hepa_installed"] <- all_decays["peak_idx"] >= hepa_install_idx
  all_decays["peak_width"] <- all_decays["valley_idx_a"] - all_decays["valley_idx_b"]
  
  decay_sum <-
    all_decays %>%
      group_by(hepa) %>%
      filter(peak_width > 3) %>%
      summarize(
        # kval
        k_val_mean = mean(k_val, na.rm = TRUE),
        k_val_median = median(k_val, na.rm = TRUE),
        # k_val_min = min(k_val, na.rm = TRUE),
        # k_val_max = max(k_val, na.rm = TRUE),
        # peak heights
        peak_hgt_mean = mean(peak_hgt, na.rm = TRUE),
        peak_hgt_median = median(peak_hgt, na.rm = TRUE),
        # peak_wdh_min = min(peak_width, na.rm = TRUE),
        # peak_wdh_max = max(peak_width, na.rm = TRUE),
        # # peak widths
        peak_wdh_mean = mean(peak_width, na.rm = TRUE),
        peak_wdh_median = median(peak_width, na.rm = TRUE),
        # peak_wdh_min = min(peak_width, na.rm = TRUE),
        # peak_wdh_max = max(peak_width, na.rm = TRUE),
        # cumulative PM
        total_plume_area = sum(cumm_pm, na.rm = TRUE),
      )
  return(decay_sum)
}
```


```{r}
# Create empty DataFrame for storing k values
plume_reduc.data <- data.frame(
  "participant_id" = numeric(0),
  "environment" = numeric(0),
  "hepa" = numeric(0),
  "type" = numeric(0),
  "k_val_mean" = numeric(0),
  "k_val_median" = numeric(0),
  # "k_val_min" = numeric(0),
  # "k_val_max" = numeric(0),
  "peak_hgt_mean" = numeric(0),
  "peak_hgt_median" = numeric(0),
  # "peak_hgt_min" = numeric(0),
  # "peak_hgt_max" = numeric(0),
  "peak_wdh_mean" = numeric(0),
  "peak_wdh_median" = numeric(0),
  # "peak_wdh_min" = numeric(0),
  # "peak_wdh_max" = numeric(0),
  "total_plume_area" = numeric(0)
)

for (id in unique(my_df$participant_id)) {
  for (env in c("indoor")) {
    for (pm in c("pm1", "pm25", "pm10")) {
      print(paste("Calculating PM", pm, "for participant", id, "in environment", env))
      res <- plume_redus(my_df, id, env, pm)
      plume_reduc.newdata <- data.frame(
        "participant_id" = id,
        "environment" = env,
        "hepa" = res$hepa,
        "type" = pm,
        "k_val_mean" = res$k_val_mean,
        "k_val_median" = res$k_val_median,
        # "k_val_min" = res$k_val_min,
        # "k_val_max" = res$k_val_max,
        "peak_hgt_mean" = res$peak_hgt_mean,
        "peak_hgt_median" = res$peak_hgt_median,
        # "peak_hgt_min" = res$peak_hgt_min,
        # "peak_hgt_max" = res$peak_hgt_max,
        "peak_wdh_mean" = res$peak_wdh_mean,
        "peak_wdh_median" = res$peak_wdh_median,
        # "peak_wdh_min" = res$peak_wdh_min,
        # "peak_wdh_max" = res$peak_wdh_max,
        "total_plume_area" = res$total_plume_area
      )
      plume_reduc.data <- rbind(plume_reduc.data, plume_reduc.newdata)
    }
  }
}
plume_reduc.data
```
## Save to file
Plume characteristics and statistics are saved in a CSV file.

```{r}
# Save plume statistic files to CSVs
write.csv(plume_reduc.data, "summary/EastBoston/SS/s_SS_M_plumes.csv")
```
