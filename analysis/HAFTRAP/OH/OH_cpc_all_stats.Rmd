# HAFTRAP Data Summarization - multiple (for CPC)

## STOP

**HAVE YOU RUN `OH_cpc_cleaning`?**
*This file loads a dataframe created from running `OH_cpc_cleaning`. Make sure you run that file first (if you haven't already) before running this file.*

This script is used to calculated summary statistics for multiple participants in the HAFTRAP study, for CPC deployments by Olin. It is largely a copy of `OH_modpm_all_stats.Rmd`, but with few modifications to deal with CPC data.

Results can be found in `summary/HAFTRAP/OH/s_OH_C_quants.csv`.

## Set up
Load libraries, define file paths, include participant IDs to be processed
```{r}
# Import relevant libraries
library(tidyverse)
```

Set working directory
```{r, setup, include=FALSE}
knitr::opts_knit$set(root.dir = "~/hepa-summer23")
```

Check for working directory
```{r}
# Check file path
if (!endsWith(getwd(), "hepa-summer23")) {
  stop("Incorrect working directory")
}
```

Participant IDs and corresponding time map tables
```{r}
# Get relevant participant IDs from OH_participants
participants <- as.character(
  na.omit(read_excel("data/HAFTRAP/OH/OH_participants.xlsx")$cpc))
```

```{r}
# Set path to data
path_to_data <- "cleaning/HAFTRAP/OH/"
```

## Load data
```{r}
# Load CPC data from RData file
load(paste0(path_to_data, "cleaned_cpc.RData"))
```
## Main Code Run
### Gather, group, and summarize
To calculate summary statistics of the data, the different measurements are gathered into one variable 'reading'. The resulting long dataframe is cleaned for NaN values and grouped. Numerous summary statistics are calculated for each type for each, case, environment, and participant.

```{r}
main_df %>%
  # Gather dataframe to create single variable for measurements
  pivot_longer(concent:inlttmp, 
               names_to = "type", values_to = "reading") %>%
  # Drop NaN, inf values for summary calculation
  filter(is.finite(reading)) %>%
  # Group by participant ID, case, environment, and type
  group_by(participant_id, case, environment, type) %>%
  
  # Calculate summary statistics and pipe to variable 'summary'
  summarise(mean = mean(reading),
            median = median(reading), 
            q5 = quantile(reading, probs = 0.05), 
            q25 = quantile(reading, probs = 0.25),
            q75 = quantile(reading, probs = 0.75),
            q95 = quantile(reading, probs = 0.95),
            sd = sd(reading),
            .groups = 'drop') -> summary
```

### Calculate percentage reduction in concentration from sham to hepa
Follows the same logic as calculating indoor-outdoor ratios. Spread to form sham/hepa columns that are used to calculate percent reduction in corresponding measurements. Then gather dataframe back to original shape.
```{r}
# Spread: Create separate sham, hepa summary statistics columns
summary_wide <- pivot_wider(summary, 
                            names_from = case, values_from = mean:sd)

# Calculate percentage reduction in all summary statistics
summary_redu <- 100*(select(summary_wide, ends_with("sham")) - 
  select(summary_wide, ends_with("hepa"))) / 
  select(summary_wide, ends_with("sham"))

# Rename computed columns to 'redu' for percentage reduction
colnames(summary_redu) <- sub("sham", "redu", colnames(summary_redu))

# Reshape data and pipe into variable 'summary_normal'
summary_wide %>%
  # Merge back with joined data-frame
  cbind(summary_redu) %>%
  # Gather: Return to original shape by removing the 'sham/hepa/redu'
  # suffixes by re-forming the case variable
  pivot_longer(mean_hepa:sd_redu, 
               names_to = c(".value", "case"), names_sep = "_") %>%
  # Filter out all NaN and Inf values
  filter_all(all_vars(!is.infinite(.))) -> summary_normal
```

## Save to file
Summary statistics are saved in a CSV file.
```{r}
# Save summary statistic files to CSVs
write.csv(summary_normal, "summary/HAFTRAP/OH/s_OH_C_quants.csv")
```