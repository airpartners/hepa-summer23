# HAFTRAP Decay Analysis (for Mod-PM)

## STOP

**HAVE YOU RUN `OH_modpm_cleaning`?**
*This file loads a dataframe created from running `OH_modpm_cleaning`. Make sure you run that file first (if you haven't already) before running this file.*

This file is used to find decay constants for the HAFTRAP Mod-PM data.

```{r}
# import necessary libraries
library(tidyverse)
library(pracma)
library(forecastML)
library(zoom)
```

```{r, setup, include=FALSE}
# set working directory
knitr::opts_knit$set(root.dir = '/home/sjatti/Desktop/hepa-summer23')
```

```{r}
# check file path for working directory
if (!endsWith(getwd(), "hepa-summer23")) {
  stop("Incorrect working directory")
}
```

```{r}
# Set path to data
path_to_data <- "data/HAFTRAP/OH/modpm/"

# Load modpm data from RData file
load(paste0(path_to_data, "cleaned_modpm.RData"))
```

```{r}
# vector of participant numbers' data to be processed (modify to analyze specific participants)
participants <- "41181"
cases = "sham"

# ("41181", "41271", "42231", "42281", "42301", "42321",
# "44241", "44621", "45361", "45411", "45451", "46591")
```

```{r}
# filter data to appropriate subset
main_df <- filter(main_df, participant_id %in% participants)
main_df <- filter(main_df, case == cases & environment == "indoor")

# round date to nearest ten minutes
main_df$date <- round_date(main_df$date, unit = "10 mins")

# fill any gaps in data
main_df %>%
  fill_gaps(7, frequency = "10 mins") %>%
  mutate(t = as.numeric(date) - as.numeric(date)[1]) %>%
  fill(pm1, pm25, pm10)
```

```{r}
# function to create a new dataframe with summary data
summary_dataframe <- function(data) {
  data %>%
    
  # group by 10-min intervals
  group_by(date) %>%
    
  # calculate mean for all groups
  summarise(mean_1 = mean(pm1), mean_2.5 = mean(pm25), mean_10 = mean(pm10))
}
```

```{r}
# create a summary dataframe
sum_main_df <- summary_dataframe(main_df)
```

```{r}
# find peaks for each particle and store in new dataframes
## can change values to accomodate dataset (mainly modify minpeakheight)
peaks_pm1 <- findpeaks(sum_main_df$mean_1,
                   nups = 1,
                   ndowns = 1,
                   minpeakheight = 8,
                   minpeakdistance = 20,
                   threshold = 0)

peaks_pm25 <- findpeaks(sum_main_df$mean_2.5,
                   nups = 1,
                   ndowns = 1,
                   minpeakheight = 8,
                   minpeakdistance = 20,
                   threshold = 0)

peaks_pm10 <- findpeaks(sum_main_df$mean_10,
                   nups = 1,
                   ndowns = 1,
                   minpeakheight = 20,
                   minpeakdistance = 20,
                   threshold = 0)
```

```{r}
# function to get first valley after peak
get_first_valleys <- function(data, peaks, min_threshold) {
  if (is.null(peaks)) {
    return(print("There are no peaks/valleys"))
  }
  # iterate through rows of peaks matrix
  valley_mat <- matrix(nrow = nrow(peaks), ncol = 2)
  for (row in 1:nrow(peaks)) { #nolint
    idx <- peaks[row, 2]
    n <- TRUE
    # create while loop to check for local minima
    while (n) {
      # if we're at the end of y, break out of loop
      if (idx == length(data)) {
        n <- FALSE
      } else {
        # otherwise, get slope (approximately)
        # checks that next 1/2/3 points are positive to consider it a valley
        ## change # of + points depending on how messy the data is
        slope <- data[idx + 1] - data[idx]
        slope2 <- data[idx + 2] - data[idx + 1]
        slope3 <- data[idx + 3] - data[idx + 2]
        if (data[idx] <= min_threshold && slope > 0 && slope2 > 0) {
          n <- FALSE
        } else {
          idx <- idx + 1
        }
      }
    }
    # set values of matrix so that column 1 is height of valley and 2 is index
    valley_mat[row, 1] <- data[idx]
    valley_mat[row, 2] <- idx
  }
  valley_mat
}
```

```{r}
# find the first valley after each peak
valley_threshold = 10

# can also set individual valley thresholds if necessary
valleys_pm1 <- get_first_valleys(sum_main_df$mean_1, peaks_pm1, valley_threshold)

valleys_pm25 <- get_first_valleys(sum_main_df$mean_2.5, peaks_pm25, valley_threshold)

valleys_pm10 <- get_first_valleys(sum_main_df$mean_10, peaks_pm10, valley_threshold)
```

```{r}
# function for peak/valley filtering
filter_peaks <- function(peaks, valleys) {
  
  peaks_valleys <- matrix(nrow = nrow(peaks), ncol = 4)
  
  peaks <- as.data.frame(peaks)
  valleys <- as.data.frame(valleys)
  
  # arranges both peaks and valleys in descending order
  valleys <- valleys %>%
    arrange(desc(V2))
  peaks <- peaks %>%
    arrange(desc(V2))
  
  # skips loop if there is only one peak
  if (nrow(peaks) == 1){
    peaks_valleys <- cbind(select(peaks, V1, V2), valleys)
  } else {
    
    # if multiple peaks detect the same valley, removes all but the last peak
    for (row in 1:(nrow(peaks) - 1)) {
      if (valleys[[row, 1]] != valleys[[row + 1, 1]]) {
        
        peaks_valleys[row, 1] <- peaks[row, 1]
        peaks_valleys[row, 2] <- peaks[row, 2]
        
        peaks_valleys[row, 3] <- valleys[row, 1]
        peaks_valleys[row, 4] <- valleys[row, 2]
      }
    }
    peaks_valleys[nrow(peaks), 1] <- peaks[nrow(peaks), 1]
    peaks_valleys[nrow(peaks), 2] <- peaks[nrow(peaks), 2]
        
    peaks_valleys[nrow(peaks), 3] <- valleys[nrow(peaks), 1]
    peaks_valleys[nrow(peaks), 4] <- valleys[nrow(peaks), 2]
  }
  
  # removes na values
  peaks_valleys <- na.omit(peaks_valleys)
  colnames(peaks_valleys) <- c("peaks_y", "peaks_x", "valleys_y", "valleys_x")

  peaks_valleys <- as.data.frame(peaks_valleys)

  # remove row if valley > peak or if final valley is above threshold
  peaks_valleys$results = ifelse(peaks_valleys$valleys_y > peaks_valleys$peaks_y | peaks_valleys$valleys_y > valley_threshold, NA, 1)
  peaks_valleys <- drop_na(peaks_valleys)
                
  return(peaks_valleys)
}
```

```{r}
# filter peaks/valleys for each dataset
peaks_valleys_pm1 <- filter_peaks(peaks_pm1, valleys_pm1)

peaks_valleys_pm25 <- filter_peaks(peaks_pm25, valleys_pm25)

peaks_valleys_pm10 <- filter_peaks(peaks_pm10, valleys_pm10)
```

```{r}
# function for exponential curve fitting for air quality data; returns 
# dataframe containing k-values of curves
curve_fitting <- function(data, peaks_valleys) {
    # Create empty dataframe for storing k values
  alphas.data <- data.frame(
    "peak_idx" = numeric(0),
    "valley_idx" = numeric(0),
    "peak_hgt" = numeric(0),
    "k_val" = numeric(0),
    "conv_tol" = numeric(0)
  )
  # Define parameters for curve fitting function for each row
 for (row in 1:nrow(peaks_valleys)) 
  {
    i_range <- peaks_valleys[row, 2]:peaks_valleys[row, 4]
    sect <- data[i_range]
    t <- i_range - peaks_valleys[row, 2] + 1
    main_df <- data.frame(t = t, y = sect)
    
    alphas.newdata <- tryCatch({
      
      # get exponential fit
      fit <- nls(y ~ SSasymp(t, yf, y0, log_alpha), data = main_df)
      
      # Get parameters of the fit
      params <- coef(fit)
      
      # Extract the log_alpha value and put it in form e^(log(a)) to get a
      log_alpha <- as.double(params["log_alpha"])
      alpha <- exp(log_alpha)
      
      # Get achieved convergence tolerance as metric for accuracy of fit
      # NOTE: R^2 value can be calculated but is not a useful metric
      # for nonlinear models
      conv <- fit$convInfo$finTol
      # Add alpha to dataframe
      alphas.newdata <- data.frame(
        "peak_idx" = c(peaks_valleys[row, 2]),
        "valley_idx" = c(peaks_valleys[row, 4]),
        "peak_hgt" = c(peaks_valleys[row, 1]),
        "k_val" = c(alpha),
        "conv_tol" = c(conv)
      )
      # can uncomment the print to see what errors are happening
      # otherwise, this ignores any errors
      }, error = function(e) { # print(e)
      }, warning = function(w) {
      }, finally = {
      })
      print(class(alphas.newdata))
      alphas.data <- rbind(alphas.data, alphas.newdata)
  }
  alphas.data <- arrange_all(alphas.data)
  return(alphas.data)
}
```

```{r}
# find the decay value (k constant) for each peak
decays_pm1 <- curve_fitting(sum_main_df$mean_1, peaks_valleys_pm1)
```


```{r}
decays_pm25 <- curve_fitting(sum_main_df$mean_2.5, peaks_valleys_pm25)
```


```{r}
decays_pm10 <- curve_fitting(sum_main_df$mean_10, peaks_valleys_pm10)
```

```{r}
# Function to plot the peaks and valleys on top of current time series
plot_peaks_valleys <- function(data, peaks_valleys) {
  plot(data,
  type = "l",
  main = "PM Concentration Over Time",
  xlab = "Time (min)",
  ylab = "Concentration",
  col = "navy")
  grid()
points(peaks_valleys[, 2], peaks_valleys[, 1], pch = 20, col = "maroon")
points(peaks_valleys[, 4], peaks_valleys[, 3], pch = 20, col = "green")
}
```

```{r}
# Plot the time series with the peaks and first valleys plotted on top
plot_peaks_valleys(sum_main_df$mean_1, peaks_valleys_pm1)

plot_peaks_valleys(sum_main_df$mean_2.5, peaks_valleys_pm25)

plot_peaks_valleys(sum_main_df$mean_10, peaks_valleys_pm10)
# can uncomment to zoom in on graphs
# zm()
```

# Code for dealing with final decay constants
## comment out when testing values (only run this section when ready to save 
data for a participant)

<!-- ```{r} -->
<!-- # uncomment and run once at the beginning to create a new empty df -->
<!-- # decay_constants_final <- matrix(nrow = 0, ncol = 4) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # function to add columns to specify case, participant, and particle -->
<!-- modify_df <- function(df, pm) { -->
<!--   df %>% -->
<!--     add_column(case = cases) %>% -->
<!--     add_column(participant = participants) %>% -->
<!--     add_column(particle = pm) -->
<!-- } -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # add columns to all dataframes -->
<!-- decays_pm1_final <- modify_df(decays_pm1, "1") -->

<!-- decays_pm25_final <- modify_df(decays_pm25, "2.5") -->

<!-- decays_pm10_final <- modify_df(decays_pm10, "10") -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # bind all particle dataframes -->
<!-- decay_constants <- rbind(decays_pm1_final, decays_pm25_final, decays_pm10_final) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # add to overall df -->
<!-- decay_constants_final <- rbind(decay_constants_final, decay_constants) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # Save final decay dataframe to CSV -->
<!-- write.csv(decay_constants_final, "summary/HAFTRAP/OH/OH_M_decay.csv") -->
<!-- ``` -->
