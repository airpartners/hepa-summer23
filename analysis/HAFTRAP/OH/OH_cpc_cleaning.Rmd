# CPC Data Cleaning
This file cleans, and calculates the I/O ratio for CPC data. Output is saved in a `cpc.RData` file that is *untracked* by Github. *All files that depend on using CPC data must be run after running this file.*

## Set up
Load libraries, define file paths, include participant IDs to be processed
```{r}
# Import relevant libraries
library(tidyverse)
library(corrplot)
library(rstatix)
library(readxl)
```

Set working directory
```{r, setup, include=FALSE}
knitr::opts_knit$set(root.dir = 'C:/Users/vkuchhal/Documents/hepa-summer23')
```

Check for working directory
```{r}
# Check file path
if (!endsWith(getwd(), "hepa-summer23")) {
  stop("Incorrect working directory")
}
```

Participant IDs and corresponding time map tables
```{r}
# Vector of participant numbers' data to be processed
participants <- c("41271", "42281", "45361", "44621", "45451")

# Read summary table of times
time_map <- read_excel(
  paste0("data/HAFTRAP/OH/", "OH_notes_summarized.xlsx")) %>%
  # Convert to appropriate variable types
  mutate(across(dt_start:dt_end, 
                  ~as.POSIXct(.x, format = "%m/%d/%Y %H:%M"))) %>%
  mutate(across(dt_start:dt_end, 
                  ~force_tz(.x, tz = "America/New_York"))) %>%
  mutate(across(participant_id:case, as.factor))
```

```{r}
# Set path to data
path_to_data <- "data/HAFTRAP/OH/cpc/"

# Set data category
data_cat <- "OH_C"
```

## Helper Function: filter by relevant times
The following functions is not part of the main pipeline to calculate summary statistics, but is used to clean and process the data. 

Each participant contains data for periods where both the sham and actual purifier was running. This function filters the relevant time periods and adds an added variable to track sham and HEPA (actual) readings.
```{r}
include_case <- function(df, person, cd) {
  df %>%
    # Select current participant
    filter(participant_id == person) %>%
    # Add case column
    mutate(case = case_when(
      # For sham periods
      # Note: 'cd' is the table 'current_dates' in function call
      between(date, cd$dt_start[cd$case == "sham"], 
              cd$dt_end[cd$case == "sham"]) ~ 'sham',
      # For HEPA periods
      between(date, cd$dt_start[cd$case == "hepa"], 
              cd$dt_end[cd$case == "hepa"]) ~ 'hepa'))
}
```


## Main Code Run
### Load all data. 
Ensure that all functions in the code blocks after this loop are loaded. Run this carefully, checking everything, and only once!
```{r}
# Initialize master dataframe for all data
all_df <- data.frame()

# Loop through each participant
for (person in participants) {
  # Loop through each environment
  for (env in c("indoor", "outdoor")) {
    # Set file path
    # Filename = data category + participant ID + environment
    file_name <- paste(data_cat, person, env, sep = "_")
    
    # File path = path to folder, type csv
    file_path <- paste0(path_to_data, file_name, ".csv")
    
    # Read csv
    df <- read_csv(file_path, show_col_types = FALSE) %>%
      # Add the environment type (e.g. indoor) and participant ID
      mutate(environment = env, participant_id = person)
    
    # Append to main dataframe
    all_df <- rbind(all_df, df)
  }
  print(paste("Loaded participant", person))
}

```

```{r}
# Warning: this code chunk may seem simple but takes FOREVER.
# Have patience. It deals with datetimes.
clean_df <- all_df %>%
  # Merge the date and time column
  unite(col = "date", `#YY/MM/DD`, `HR:MN:SC`, sep = " ") %>%
  # Convert to datetime object
  mutate(date = as.POSIXct(date, format = "%y/%m/%d %H:%M:%S", 
                           tz = "America/New_York")) %>%
  # Remove repeat readings
  distinct(participant_id, date, environment, .keep_all = TRUE)
```



```{r}
# Filter by time to find whether sham or hepa
case_df <- data.frame()
for (person in participants) {
  # Filter indoor (dates match outdoor) and by current participant
  current_dates <- time_map %>% 
    filter(environment == "indoor") %>%
    filter(participant_id == person)
  # Filter by date for sham and hepa (see helper function)
  df <- include_case(clean_df, person, current_dates)
  # Append to overall dataframe
  case_df <- rbind(case_df, df)
}
```

```{r}
# Quick filtering:

main_df <- case_df %>%
  # Pump flow needs to be greater than 250 for proper functioning
  filter(smpflow > 250) %>%
  # Drop pump flow variable
  select(-smpflow) %>%
  # Filter 
  # Remove values that aren't in relevant time range
  drop_na() %>%
  # Make factors
  mutate(across(c(environment, case, participant_id), as.factor)) 
  
```


### Calculate ratio of indoor and outdoor concentration
To do so, the dataframe is 'spread' to form separate indoor/outdoor columns that are then divided by each other to calculate the ratio. After calculating the ratio, the dataframe is 'gathered' back up to its original shape.
```{r}
# Spread: Create separate indoor and outdoor columns for measurements
main_df_wide <- pivot_wider(main_df,
                  names_from = environment,
                  values_from = c(concent, inlttmp))

# Divide indoor by outdoor to calculate ratios
df_ratio <- select(main_df_wide, ends_with("indoor"))/
  select(main_df_wide, ends_with("outdoor"))

# Rename computed columns to ratio
colnames(df_ratio) <- sub("indoor", "ratio", colnames(df_ratio))

# Merge back with joined data-frame
main_df_wide <- cbind(main_df_wide, df_ratio)

# Gather: Return to original shape by re-forming the environment variable
main_df <- pivot_longer(main_df_wide, 
                               concent_indoor:inlttmp_ratio, 
                               names_to = c(".value", "environment"), 
                               names_sep = "_") %>%
  mutate(environment = as.factor(environment))
```

### Save Data
The `main_df` dataframe is saved to `cleaned_cpc.RData`
```{r}
save(main_df, file = paste0(path_to_data, "cleaned_cpc.RData"))
```
