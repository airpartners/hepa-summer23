# HAFTRAP Data Cleaning and Summaries - multiple (for CPC)

## STOP

**HAVE YOU RUN `OH_modpm_cleaning` AND `OH_cpc_cleaning`?**
*This file loads dataframes created from running `OH_modpm_cleaning` AND `OH_cpc_cleaning`. Make sure you run those files first (if you haven't already) before running this file.*


This script is a combination of `OH_modpm_all_stats` and `OH_cpc_all_stats` to concurrently process CPC and Mod-PM data. It calculates summary statistics for variables from both Mod-PM and CPC readings, and compare variables.

Results can be found in the folder`summary/HAFTRAP/OH/joint/`.

## Set up
Load libraries, define file paths, include participant IDs to be processed
```{r}
# Import relevant libraries
library(tidyverse)
library(corrplot)
library(rstatix)
```

Set working directory
```{r, setup, include=FALSE}
knitr::opts_knit$set(root.dir = 'C:/Users/vkuchhal/Documents/hepa-summer23')
```

Check for working directory
```{r}
# Check file path
if (!endsWith(getwd(), "hepa-summer23")) {
  stop("Incorrect working directory")
}
```

Participant IDs and corresponding time map tables
```{r}
# Vector of participant numbers' data to be processed
participants <- c("41271", "42281", "45361", "44621", "45451")

### Set paths
# # For CPC
# Set path to data
path_to_data_C <- "data/HAFTRAP/OH/cpc/"

# # For Mod-PM
# Set path to data
path_to_data_M <- "data/HAFTRAP/OH/modpm/"
```

## Load data

Mod-PM
```{r}
# Load Mod-PM data from RData file
load(paste0(path_to_data_M, "cleaned_modpm.RData"))

# Create copy of main_df, and delete original
modpm_df <- main_df
rm(main_df)
```

CPC - filter data to whole minutes
```{r}
# Load CPC data from RData file
load(paste0(path_to_data_C, "cleaned_cpc.RData"))

# Create copy of main_df
cpc_df <- main_df %>%
  # Mod-PM data is sampled by whole minute, filter CPC data to match
  filter(second(main_df$date) == 0)

# Delete original
rm(main_df)
```


## Helper Function: calculating correlation coefficients
The following function is not part of the main pipeline to calculate summary statistics, but is used to clean and process the data. 

Correlation coefficients tell us a lot about relationships between variables. This function calculates the correlation matrix for a particular case for a single participant and reshapes it into a paired-list format
```{r}
# Function to calculate correlation matrices
get_corr <- function(df, p, c) {
  df %>%
    # Filter for case
    filter(participant_id == p, case == c) %>%
    # Select all columns except date
    select_if(is.numeric) %>%
    # Remove NaN values
    drop_na() %>%
    # Calculate correlations
    cor_mat() %>%
    # Reshape into paired-list format
    cor_gather()
}
```

## Main Code Run

### Merge CPC and Mod-PM Data
Merge is conducted over matching dates for each participant in a particlular environment and case
```{r}
main_df <- merge(cpc_df, modpm_df, 
                   by = c("date", "participant_id", 
                          "environment", "case"))
```

### Calculate correlation matrices
Helps better understand the relationship between different variables in sham and true HEPA conditions for each participant. Matrices are reshaped into longer pair format for stacking all the data into single dataframe. (Warning: this code takes a while to run.)

```{r}
# Spread: Create separate indoor, outdoor columns for particle concentration
main_df_wide <- pivot_wider(main_df,
                  names_from = environment,
                  values_from = c(concent:temp))

# Create dataframe to hold correlation coefficients
corr_df <- data.frame()
# Loop through each participant
for (person in participants) {
  # Loop through each case
  for (case in c("sham", "hepa")) {
    # Use wide dataframe where indoor/outdoor are separate columns
    main_df_wide %>%
      # Get correlation coefficients (look at helper function)
      get_corr(person, case) %>%
      # Add the case and participant ID
      mutate(case = case, participant_id = person) -> df
    # Append to main dataframe
    corr_df <- rbind(corr_df, df)
    print(paste("Computed correlation coefficients for", person, case))
  }
}
```

### Gather, group, and summarize
To calculate summary statistics of the data, the different measurements are gathered into one variable 'reading'. The resulting long dataframe is cleaned for NaN values and grouped. Numerous summary statistics are calculated for each type for each, case, environment, and participant.

```{r}
main_df %>%
  # Gather dataframe to create single variable for measurements
  pivot_longer(concent:temp, 
               names_to = "type", values_to = "reading") %>%
  # Drop NaN, inf values for summary calculation
  filter(is.finite(reading)) %>%
  # Group by participant ID, case, environment, and type
  group_by(participant_id, case, environment, type) %>%
  
  # Calculate summary statistics and pipe to variable 'summary'
  summarise(mean = mean(reading),
            median = median(reading), 
            q5 = quantile(reading, probs = 0.05), 
            q25 = quantile(reading, probs = 0.25),
            q75 = quantile(reading, probs = 0.75),
            q95 = quantile(reading, probs = 0.95),
            sd = sd(reading),
            .groups = 'drop') -> summary
```


### Calculate percentage reduction in concentration from sham to hepa
Follows the same logic as calculating indoor-outdoor ratios. Spread to form sham/hepa columns that are used to calculate percent reduction in corresponding measurements. Then gather dataframe back to original shape.
```{r}
# Spread: Create separate sham, hepa summary statistics columns
summary_wide <- pivot_wider(summary, 
                            names_from = case, values_from = mean:sd)

# Calculate percentage reduction in all summary statistics
summary_redu <- 100*(select(summary_wide, ends_with("sham")) - 
  select(summary_wide, ends_with("hepa"))) / 
  select(summary_wide, ends_with("sham"))

# Rename computed columns to 'redu' for percentage reduction
colnames(summary_redu) <- sub("sham", "redu", colnames(summary_redu))

# Reshape data and pipe into variable 'summary_normal'
summary_wide %>%
  # Merge back with joined data-frame
  cbind(summary_redu) %>%
  # Gather: Return to original shape by removing the 'sham/hepa/redu'
  # suffixes by re-forming the case variable
  pivot_longer(mean_hepa:sd_redu, 
               names_to = c(".value", "case"), names_sep = "_") %>%
  # Filter out all NaN and Inf values
  filter_all(all_vars(!is.infinite(.))) %>%
  # Change to factors
  mutate(across(c(type, case), as.factor)) -> summary_normal
```

## Save to file
Summary statistics are saved in a series of csv files. The naming convention of these files is specified by in `data_guide.md`
```{r}
# Save summary statistic files to CSVs
write.csv(summary_normal, "summary/HAFTRAP/OH/s_OH_MC_quants.csv")
write.csv(corr_df, "summary/HAFTRAP/OH/s_OH_MC_corr.csv")
```