# SCOPE HAFTRAP Data Summarization

## STOP

**HAVE YOU RUN `SC_all_cleaning`?**
*This file loads a dataframe created from running `SC_all_cleaning`. Make sure you run that file first (if you haven't already) before running this file.*

This script is used to calculated summary statistics for multiple participants in the HAFTRAP study, for all deployments in the SCOPE project.

Results can be found in `summary/HAFTRAP/SC/s_SC_RASCT_quants.csv`.

## Set up
Load libraries, define file paths, include participant IDs to be processed
```{r}
# Import relevant libraries
library(tidyverse)
library(openair)
```

Set working directory
```{r, setup, include=FALSE}
knitr::opts_knit$set(root.dir = "~/hepa-summer23")
```

```{r}
# Get file path
if (!endsWith(getwd(), "hepa-summer23")) {
  stop("Incorrect working directory")
}
```

```{r}
# Set path to data
path_to_data <- "cleaning/HAFTRAP/SC/"
```

## Load data
```{r}
# Load Mod-PM data from RData file
load(paste0(path_to_data, "cleaned_everything.RData"))
```

## Create some exploratory OpenAir plots
```{r}
# choose indoor or outdoor
env <- "indoor"

# choose HEPA on/off
cs <- c("off", "on")

# choose participant(s)
part <- c("1", "2", "3", "4")

#filter by in vs out, on vs off vs all, and participants
df <- filter(main_df, environment == env, participant_id == part, case == cs)


#timePlot(df, pollutant = c("mcpc_counts", "acsm_org", "acsm_so4", "acsm_f43", "acsm_f44"), y.relation = "free")

#linearRelation(df, x = "mcpc_counts", y = "mod_pm1num", period = "day.hour")

# diurnals
timeVariation(df, pollutant = c( "t200u_no", "t200u_no2", "t300_co"), ylab = "PNC (ug/m3)", normalise = TRUE)
timeVariation(df, pollutant = c( "mcpc_counts", "acsm_org", "acsm_ratio_55_57"), ylab = "PNC (ug/m3)", normalise = TRUE)
#timeVariation(df, pollutant = c( "sems_sum50", "sems_sum100", "sems_sum1000"), ylab = "PNC (ug/m3)", normalise = TRUE)

#timeVariation(df, pollutant = c("acsm_org", "acsm_ratio_55_57"), ylab = "PNC (ug/m3)", normalise = TRUE)
#timeVariation(df, pollutant = c("acsm_org", "acsm_f57"), ylab = "ug/m3")
timeVariation(df, pollutant = "mcpc_counts", col = "firebrick")
timeVariation(df, pollutant = "acsm_org", col = "firebrick")
timeVariation(df, pollutant = "mod_pm25", col = "firebrick")

#scatterPlot(df, x = "mod_pm1", y = "acsm_org", method = "hexbin", col= "jet")

```

## Helper Function: Calculate summary statistics
Provided a given grouped dataframe, calculate all relevant summary statistics
```{r}
my_summarise <- function(grouped_df) {
  grouped_df %>%
    summarise(mean = mean(reading),
            median = median(reading), 
            q5 = quantile(reading, probs = 0.05), 
            q25 = quantile(reading, probs = 0.25),
            q75 = quantile(reading, probs = 0.75),
            q95 = quantile(reading, probs = 0.95),
            sd = sd(reading),
            .groups = 'drop')
}
```


## Main Code Run
### Gather, group, and summarize
To calculate summary statistics of the data, the different measurements (PM1,  PM2.5, PM10, PM1_num, and temperature) are gathered into one variable 'reading'. The resulting long dataframe is cleaned for NaN values and grouped. Numerous summary statistics are calculated for each type for each, case, environment, and participant.

```{r}
main_df_long <- main_df %>%
  # Gather dataframe to create single variable for measurements
  pivot_longer(!c(date, environment, participant_id, case), 
               names_to = "type", values_to = "reading") %>%
  # Drop NaN, inf values for summary calculation
  filter(is.finite(reading)) 

# Calculate summary statistics for each participant
participant_summary <- main_df_long %>%
  # Group by participant ID, case, environment, and type
  group_by(participant_id, case, environment, type) %>%
  # Calculate summary statistics
  my_summarise()
  
# Calculate summary statistics over all the data
overall_summary <- main_df_long %>%
  # Group by case, environment, and type
  group_by(case, environment, type) %>%
  # Calculate summary statistics
  my_summarise() %>%
  # Add participant ID column as 'all'
  mutate(participant_id = "all")
```

```{r}
# Bind together participant and overall summary statistics
summary <- rbind(participant_summary, overall_summary)
```


### Calculate percentage reduction in concentration from sham to hepa
Follows the same logic as calculating indoor-outdoor ratios. Spread to form 
sham/hepa columns that are used to calculate percent reduction in corresponding
summary pollution concentrations. Then gather dataframe back to original shape.
```{r}
# Spread: Create separate sham, hepa summary statistics columns
summary_wide <- pivot_wider(summary, 
                            names_from = case, values_from = mean:sd)

# Calculate percentage reduction in all summary statistics
summary_redu <- 100*(select(summary_wide, ends_with("off")) - 
  select(summary_wide, ends_with("on"))) / 
  select(summary_wide, ends_with("off"))

# Rename computed columns to 'redu' for percentage reduction
colnames(summary_redu) <- sub("off", "redu", colnames(summary_redu))

# Reshape data and pipe into variable 'summary_normal'
summary_wide %>%
  # Merge back with joined data-frame
  cbind(summary_redu) %>%
  # Gather: Return to original shape by removing the 'sham/hepa/redu'
  # suffixes by re-forming the case variable
  pivot_longer(mean_off:sd_redu,
               names_to = c(".value", "case"), names_sep = "_") %>%
  # Filter out all NaN and Inf values
  filter_all(all_vars(!is.infinite(.))) -> summary_normal
```

## Save to file
Summary statistics are saved in a CSV file.
```{r}
# Save summary statistic files to CSVs
write.csv(summary_normal, "summary/HAFTRAP/SC/s_SC_RASCT_quants.csv")
```